{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207be73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open txt file\n",
    "with open ('/Users/huopeiyang/Desktop/Calvino, Italo - Invisible Cities (transl. William Weaver) (2012) - libgen.li.txt') as in_file:\n",
    "    text=in_file.read()\n",
    "with open ('/Users/huopeiyang/Desktop/invisible cities_ header of each chapter.txt') as in_file:\n",
    "    header=in_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = r\"_(.+?)__\"\n",
    "header_each=re.findall(regex, header,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc006b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = r\"\\n[A-Z]+[\\s&]*[A-Z\\s]+\\s*[0-9]\\s*\\n\\n(.+?)\\n\\n\\n\"\n",
    "content_each=re.findall(regex, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f6ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_each.extend(header_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c48a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48622fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/Users/huopeiyang/Desktop/thesis/selected_reviews.csv')\n",
    "review=df['review'].tolist()\n",
    "timestamps=df['post_time'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7e25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove short or space \n",
    "new_review=[]\n",
    "for r in review:\n",
    "    new=tokenize_comments_to_sentences(r)\n",
    "    for n in new:\n",
    "        if len(n.split(' '))>5:\n",
    "            new_review.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3d8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find quotation and move them from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b688aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = r\"“(.+?)”\\s*\"\n",
    "\n",
    "def remove_quotes(comment):\n",
    "    return re.sub(regex, '', comment)\n",
    "\n",
    "comments_without_quotes = [remove_quotes(r) for r in review]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c8d3d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = r\"“(.+?)”\\s*\"\n",
    "\n",
    "def find_quotes(comment):\n",
    "    return re.findall(regex, comment)\n",
    "quotes = [find_quotes(r) for r in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98a840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_year=df['year'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_year=[]\n",
    "for index,q in enumerate(quotes):\n",
    "    if len(q)!=0:\n",
    "        quote_year.append((q,review_year[index])) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12a47b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_without_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c448b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps=df['post_time'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e118c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t=[]\n",
    "for index,r in enumerate(comments_without_quotes):\n",
    "    r_t.append((r,timestamps[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6344e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review_cleaned=[]\n",
    "for r in comments_without_quotes:\n",
    "    new=tokenize_comments_to_sentences(r)\n",
    "    for n in new:\n",
    "        if len(n.split(' '))>5:\n",
    "            new_review_cleaned.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfffae",
   "metadata": {},
   "source": [
    "### create sentence data for BERTopic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ff29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence_timestamps = []\n",
    "sen_ts=[]\n",
    "\n",
    "# Iterate over each comment and its corresponding timestamp\n",
    "for comment, timestamp in r_t:\n",
    "    # Split the comment into sentences\n",
    "    comment_sentences = tokenize_comments_to_sentences(comment)  # This is a simple way to split sentences, but you might need a more advanced method depending on your data\n",
    "    # Append the sentences and the corresponding timestamp to the lists\n",
    "    for sentence in comment_sentences:\n",
    "        if len(sentence.split(' '))>5:\n",
    "            sentences.append(sentence)\n",
    "            sentence_timestamps.extend([timestamp])\n",
    "            sen_ts.append((sentence,timestamp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e65581dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cee575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_chars(text):\n",
    "    return re.sub(r'&amp;|\\n|\\t', ' ', text)\n",
    "\n",
    "new_comments_html = [replace_chars(comment) for comment in new_review_cleaned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7967a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c877360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huopeiyang/anaconda3/envs/tf/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/huopeiyang/anaconda3/envs/tf/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/huopeiyang/anaconda3/envs/tf/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/huopeiyang/anaconda3/envs/tf/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c29307e2a94b75966a5ec7c30c81e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7821</td>\n",
       "      <td>-1_city_streets_inhabitants_poetic</td>\n",
       "      <td>[city, streets, inhabitants, poetic, place, im...</td>\n",
       "      <td>[ And the mind refuses to accept more faces, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "      <td>0_prose_novels_favorite authors_fables</td>\n",
       "      <td>[prose, novels, favorite authors, fables, fict...</td>\n",
       "      <td>[Imagine, if you will, a swirling, dynamic mix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>1_felt like_glad did_patience_did really</td>\n",
       "      <td>[felt like, glad did, patience, did really, di...</td>\n",
       "      <td>[ It is becoming irreparably squashed and torn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>625</td>\n",
       "      <td>2_visible cities_cities story_hidden cities_ci...</td>\n",
       "      <td>[visible cities, cities story, hidden cities, ...</td>\n",
       "      <td>[Absolutely failing to even piece together a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>523</td>\n",
       "      <td>3_kublai describing cities_mongol emperor kubl...</td>\n",
       "      <td>[kublai describing cities, mongol emperor kubl...</td>\n",
       "      <td>[ back then i thought this was a beautifully w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>98_cities lost little_cities stay lost_cities ...</td>\n",
       "      <td>[cities lost little, cities stay lost, cities ...</td>\n",
       "      <td>[ Or perhaps, speaking of other cities, I have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>99_city traveller finds_new city traveller_cit...</td>\n",
       "      <td>[city traveller finds, new city traveller, cit...</td>\n",
       "      <td>[\"Arriving at each new city, the traveler find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "      <td>100_men dreamed chasing_men dreams chasing_pat...</td>\n",
       "      <td>[men dreamed chasing, men dreams chasing, path...</td>\n",
       "      <td>[ They laid the streets, each following his pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>101_true exist hypothesis_exist hypothesis tru...</td>\n",
       "      <td>[true exist hypothesis, exist hypothesis true,...</td>\n",
       "      <td>[ So the other hypothesis is true: they exist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>102_imaginary city uncovering_illusory metropo...</td>\n",
       "      <td>[imaginary city uncovering, illusory metropoli...</td>\n",
       "      <td>[ It may be that he is creating them all out o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "0       -1   7821                 -1_city_streets_inhabitants_poetic   \n",
       "1        0    873             0_prose_novels_favorite authors_fables   \n",
       "2        1    663           1_felt like_glad did_patience_did really   \n",
       "3        2    625  2_visible cities_cities story_hidden cities_ci...   \n",
       "4        3    523  3_kublai describing cities_mongol emperor kubl...   \n",
       "..     ...    ...                                                ...   \n",
       "99      98     21  98_cities lost little_cities stay lost_cities ...   \n",
       "100     99     21  99_city traveller finds_new city traveller_cit...   \n",
       "101    100     21  100_men dreamed chasing_men dreams chasing_pat...   \n",
       "102    101     20  101_true exist hypothesis_exist hypothesis tru...   \n",
       "103    102     20  102_imaginary city uncovering_illusory metropo...   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [city, streets, inhabitants, poetic, place, im...   \n",
       "1    [prose, novels, favorite authors, fables, fict...   \n",
       "2    [felt like, glad did, patience, did really, di...   \n",
       "3    [visible cities, cities story, hidden cities, ...   \n",
       "4    [kublai describing cities, mongol emperor kubl...   \n",
       "..                                                 ...   \n",
       "99   [cities lost little, cities stay lost, cities ...   \n",
       "100  [city traveller finds, new city traveller, cit...   \n",
       "101  [men dreamed chasing, men dreams chasing, path...   \n",
       "102  [true exist hypothesis, exist hypothesis true,...   \n",
       "103  [imaginary city uncovering, illusory metropoli...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [ And the mind refuses to accept more faces, m...  \n",
       "1    [Imagine, if you will, a swirling, dynamic mix...  \n",
       "2    [ It is becoming irreparably squashed and torn...  \n",
       "3    [Absolutely failing to even piece together a f...  \n",
       "4    [ back then i thought this was a beautifully w...  \n",
       "..                                                 ...  \n",
       "99   [ Or perhaps, speaking of other cities, I have...  \n",
       "100  [\"Arriving at each new city, the traveler find...  \n",
       "101  [ They laid the streets, each following his pu...  \n",
       "102  [ So the other hypothesis is true: they exist ...  \n",
       "103  [ It may be that he is creating them all out o...  \n",
       "\n",
       "[104 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from bertopic import BERTopic \n",
    "from sentence_transformers import SentenceTransformer, util \n",
    "from umap import UMAP \n",
    "from hdbscan import HDBSCAN \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from bertopic.vectorizers import ClassTfidfTransformer \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer#'descriptions','described','describing','describe',\n",
    "\n",
    "\n",
    "\n",
    "custom_stopwords=['travels','literature','italo','travel','calvinos','calvin','calvino','reading','read','novel','books','book','venice','invisible','polo','marco','khan','polos']\n",
    "all_stopwords=list(ENGLISH_STOP_WORDS)+ custom_stopwords\n",
    "vectorizer_model = CountVectorizer(stop_words= all_stopwords, ngram_range=(1, 3)) \n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "representation_model = KeyBERTInspired()\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(new_comments_html, show_progress_bar=True)\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, random_state=42,\n",
    "                  min_dist=0.0, metric='cosine')\n",
    "\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model,\n",
    "                      ctfidf_model=ctfidf_model,\n",
    "                      representation_model=representation_model,\n",
    "                      embedding_model=sentence_model,\n",
    "                      min_topic_size=20,\n",
    "                      umap_model=umap_model)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(new_comments_html)\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d2cae",
   "metadata": {},
   "source": [
    "### reading each cluster and summarize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "50341634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imaginary city uncovering', 'illusory metropolises mind', 'possible forms city', 'truth illusory metropolises', 'says city explained', 'illusory metropolises', 'rome keeping', 'imagination recreating details', 'forms city talking', 'know maybe city']\n",
      "[' It may be that he is creating them all out of his imagination, or perhaps he is recreating details of his native Venice over and over again, or perhaps he is simply recounting some of the countless possible forms a city might take', ' Next week he would be in his beloved Venice, dreaming up the world, a world more real than reality, with all the ingredients needed to construct a city - memories, desires, signs, skies, trade, eyes, sounds, shapes, names and the dead', ' Is he talking about one city, Venice? Is he making it up? What is he telling us about the world, about people and their ways of creating and living in the world? And yet, what amazing cities he has conceived: doubles of each other, lost pasts, deconstructed walls, canals in the desert']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('imaginary city uncovering', 0.5024779),\n",
       " ('illusory metropolises mind', 0.40253592),\n",
       " ('possible forms city', 0.3903371),\n",
       " ('truth illusory metropolises', 0.38869002),\n",
       " ('says city explained', 0.38325673),\n",
       " ('illusory metropolises', 0.3665496),\n",
       " ('rome keeping', 0.356018),\n",
       " ('imagination recreating details', 0.35419402),\n",
       " ('forms city talking', 0.35295182),\n",
       " ('know maybe city', 0.34024963)]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number=102\n",
    "topic=number+1\n",
    "representative=topic_model.get_topic_info()['Representative_Docs'].tolist()\n",
    "representative_word=topic_model.get_topic_info()['Representation'].tolist()\n",
    "\n",
    "word=representative_word[topic]\n",
    "doc=representative[topic]\n",
    "\n",
    "print(word)\n",
    "print (doc)\n",
    "topic_model.get_topic(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c7b9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "label={0:'genre',1:'structure',2:'personal reflections',3:'structure',4:'personal reflections',5:'structure',6:'personal reflections',7:'structure',8:'personal reflections',9:'quote',10:'genre',\n",
    "       11:'recommend',12:'recommend',13:'genre',14:'personal reflections',15:'genre',16:'recommend',17:'genre',18:'Venice',19:'structure',20:'genre',\n",
    "      21:'structure',22:'genre',23:'personal reflections',24:'recommend',25:'genre',26:'quote',27:'recommend',28:'genre',29:'structure',30:'recommend',\n",
    "       31:'structure',32:'Venice',33:'personal reflections',34:'recommend',35:'personal reflections',36:'personal reflections',37:'genre',38:'recommend',39:'quote',40:'structure',\n",
    "       41:'genre',42:'recommend',43:'weird',44:'genre',45:'structure',46:'genre',47:'personal reflections',48:'recommend',49:\"If On A Winter's Night a Traveler\",50:'quote',\n",
    "       51:'quote',52:'structure',53:'quote',54:'personal reflections',55:'recommend',56:'recommend',57:'quote',58:'genre',59:'genre',60:'structure',\n",
    "       61:'personal reflections',62:'recommend',63:'quote',64:'quote',65:'weird',66:'quote',67:'quote',68:'structure',69:'quote',70:'structure',\n",
    "       71:'genre',72:\"If On A Winter's Night a Traveler\",73:'genre',74:'quote',75:'quote',76:'genre',77:'recommend',78:'quote',79:'genre',80:'recommend',\n",
    "       81:'personal reflections',82:'quote',83:'recommend',84:'recommend',85:'recommend',86:'quote',87:'recommend',88:'quote',89:'recommend',90:'genre',\n",
    "       91:'quote',92:'weird',93:'personal reflections',94:'recommend',95:'quote',96:'quote',97:'weird',98:'quote',99:'quote',100:'quote',\n",
    "       101:'quote',102:'Venice'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86fb99d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre: 20\n",
      "structure: 14\n",
      "personal reflections: 14\n",
      "quote: 25\n",
      "recommend: 21\n",
      "Venice: 3\n",
      "weird: 4\n",
      "If On A Winter's Night a Traveler: 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "value_frequencies = Counter(label.values())\n",
    "\n",
    "# Print the frequencies\n",
    "for value, frequency in value_frequencies.items():\n",
    "    print(f\"{value}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5704192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85abc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = topic_model.reduce_outliers(new_comments_html, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "141b3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(new_comments_html, topics=new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e447ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df=topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb88389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>-1_read_over_book_shoutout</td>\n",
       "      <td>[read, over, book, shoutout, rec, auris, tranq...</td>\n",
       "      <td>[ And the mind refuses to accept more faces, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>905</td>\n",
       "      <td>0_calvino_his_to_is</td>\n",
       "      <td>[calvino, his, to, is, read, and, this, that, ...</td>\n",
       "      <td>[Imagine, if you will, a swirling, dynamic mix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>817</td>\n",
       "      <td>1_it_didn_but_just</td>\n",
       "      <td>[it, didn, but, just, was, me, get, really, do...</td>\n",
       "      <td>[ It is becoming irreparably squashed and torn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>662</td>\n",
       "      <td>2_invisible_cities_is_of</td>\n",
       "      <td>[invisible, cities, is, of, to, in, and, as, t...</td>\n",
       "      <td>[Absolutely failing to even piece together a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>659</td>\n",
       "      <td>3_kublai_marco_khan_polo</td>\n",
       "      <td>[kublai, marco, khan, polo, visited, cities, h...</td>\n",
       "      <td>[ back then i thought this was a beautifully w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>98</td>\n",
       "      <td>195</td>\n",
       "      <td>98_little_lost_speaking_already</td>\n",
       "      <td>[little, lost, speaking, already, bit, perhaps...</td>\n",
       "      <td>[ Or perhaps, speaking of other cities, I have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>99</td>\n",
       "      <td>172</td>\n",
       "      <td>99_longer_lies_foreign_wait</td>\n",
       "      <td>[longer, lies, foreign, wait, possess, arrivin...</td>\n",
       "      <td>[\"Arriving at each new city, the traveler find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>100_streets_built_men_woman</td>\n",
       "      <td>[streets, built, men, woman, walls, dream, arc...</td>\n",
       "      <td>[ They laid the streets, each following his pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>101</td>\n",
       "      <td>139</td>\n",
       "      <td>101_exist_they_true_real</td>\n",
       "      <td>[exist, they, true, real, hypothesis, do, norm...</td>\n",
       "      <td>[ So the other hypothesis is true: they exist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>102_venice_he_describing_mind</td>\n",
       "      <td>[venice, he, describing, mind, his, creating, ...</td>\n",
       "      <td>[ It may be that he is creating them all out o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                             Name  \\\n",
       "0       -1     37       -1_read_over_book_shoutout   \n",
       "1        0    905              0_calvino_his_to_is   \n",
       "2        1    817               1_it_didn_but_just   \n",
       "3        2    662         2_invisible_cities_is_of   \n",
       "4        3    659         3_kublai_marco_khan_polo   \n",
       "..     ...    ...                              ...   \n",
       "99      98    195  98_little_lost_speaking_already   \n",
       "100     99    172      99_longer_lies_foreign_wait   \n",
       "101    100     92      100_streets_built_men_woman   \n",
       "102    101    139         101_exist_they_true_real   \n",
       "103    102     86    102_venice_he_describing_mind   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [read, over, book, shoutout, rec, auris, tranq...   \n",
       "1    [calvino, his, to, is, read, and, this, that, ...   \n",
       "2    [it, didn, but, just, was, me, get, really, do...   \n",
       "3    [invisible, cities, is, of, to, in, and, as, t...   \n",
       "4    [kublai, marco, khan, polo, visited, cities, h...   \n",
       "..                                                 ...   \n",
       "99   [little, lost, speaking, already, bit, perhaps...   \n",
       "100  [longer, lies, foreign, wait, possess, arrivin...   \n",
       "101  [streets, built, men, woman, walls, dream, arc...   \n",
       "102  [exist, they, true, real, hypothesis, do, norm...   \n",
       "103  [venice, he, describing, mind, his, creating, ...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [ And the mind refuses to accept more faces, m...  \n",
       "1    [Imagine, if you will, a swirling, dynamic mix...  \n",
       "2    [ It is becoming irreparably squashed and torn...  \n",
       "3    [Absolutely failing to even piece together a f...  \n",
       "4    [ back then i thought this was a beautifully w...  \n",
       "..                                                 ...  \n",
       "99   [ Or perhaps, speaking of other cities, I have...  \n",
       "100  [\"Arriving at each new city, the traveler find...  \n",
       "101  [ They laid the streets, each following his pu...  \n",
       "102  [ So the other hypothesis is true: they exist ...  \n",
       "103  [ It may be that he is creating them all out o...  \n",
       "\n",
       "[104 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c8de5",
   "metadata": {},
   "source": [
    "### Calculate the proportion of each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74269294",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_topic=topic_df['Topic'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8f4a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count=topic_df['Count'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74839515",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_topic=[]\n",
    "for index,name in label.items():\n",
    "    if name=='genre':\n",
    "        pr_topic.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abc6585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824.319415217632\n",
      "0.20007752796544467\n",
      "3613\n"
     ]
    }
   ],
   "source": [
    "value=0\n",
    "for index,t in enumerate(column_topic):\n",
    "    if t in pr_topic:\n",
    "        value+= column_count[index]\n",
    "print((value/18058)*4120)\n",
    "print(value/18058)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b3275",
   "metadata": {},
   "source": [
    "### saperate data into themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "74d22c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sent=[]\n",
    "for index,t in enumerate(new_topics):\n",
    "    if t in genre_topic:\n",
    "        genre_sent.append((new_comments_html[index],sentence_timestamps[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6049799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genre_sents.json', 'w') as f:\n",
    "    json.dump(genre_sent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96ca8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_topic=[]\n",
    "for index,name in label.items():\n",
    "    if name=='recommend':\n",
    "        recommend_topic.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "617f0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_sent=[]\n",
    "for index,t in enumerate(new_topics):\n",
    "    if t in recommend_topic:\n",
    "        recommend_sent.append((new_comments_html[index],sentence_timestamps[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recommend_sent.json', 'w') as f:\n",
    "    json.dump(recommend_sent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e01879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#personal reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f34048",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_topic=[]\n",
    "for index,name in label.items():\n",
    "    if name=='personal reflections':\n",
    "        recommend_topic.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39bb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_sent=[]\n",
    "for index,t in enumerate(new_topics):\n",
    "    if t in personal_topic:\n",
    "        personal_sent.append((new_comments_html[index],sentence_timestamps[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('personal_reflection_sents.json', 'w') as f:\n",
    "    json.dump(recommend_sent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e4a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1039090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befa32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e0cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b78524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1e3b9b",
   "metadata": {},
   "source": [
    "### others work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5e68482",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_topic=[]\n",
    "for index,name in label.items():\n",
    "    if name=='quote':\n",
    "        quote_topic.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92622804",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_sent=[]\n",
    "for index,t in enumerate(new_topics):\n",
    "    if t in recommend_topic:\n",
    "        recommend_sent.append((new_comments_html[index],sentence_timestamps[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "899a9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_topic=[]\n",
    "for index,name in label.items():\n",
    "    if name=='structure':\n",
    "        structure_topic.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8797a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "#other topics\n",
    "print(4120-851-740-773-824-701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "4a0f821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_topic = []\n",
    "for key, value in label.items():\n",
    "    if value == 'genre':\n",
    "        genre_topic.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "42d85daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_topic = []\n",
    "for key, value in label.items():\n",
    "    if value == 'structure':\n",
    "        structure_topic.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "6c4747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_topic = []\n",
    "for key, value in label.items():\n",
    "    if value == 'personal reflections':\n",
    "        personal_topic.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "43147e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_topic = []\n",
    "for key, value in label.items():\n",
    "    if value == 'topic':\n",
    "        topic_topic.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "b027958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_topic = []\n",
    "for key, value in label.items():\n",
    "    if value == 'quote':\n",
    "        quote_topic.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "438a7bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_topic=[]\n",
    "for index,topic in enumerate(new_topics):\n",
    "    sentences_topic.append((new_review_cleaned[index],topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "f9143608",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sentence=[]\n",
    "for sentence,topic in sentences_topic:\n",
    "    if topic in genre_topic:\n",
    "        genre_sentence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "72c85ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the list to a text file\n",
    "with open('genre_sentence.txt', 'w') as f:\n",
    "    for item in genre_sentence:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "dca10494",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_sentence=[]\n",
    "for sentence,topic in sentences_topic:\n",
    "    if topic in structure_topic:\n",
    "        structure_sentence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "8ee92a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list to a text file\n",
    "with open('structure_sentence.txt', 'w') as f:\n",
    "    for item in structure_sentence:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "31572d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sentence=[]\n",
    "for sentence,topic in sentences_topic:\n",
    "    if topic in topic_topic:\n",
    "        topic_sentence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "47995ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list to a text file\n",
    "with open('topic_sentence.txt', 'w') as f:\n",
    "    for item in topic_sentence:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
